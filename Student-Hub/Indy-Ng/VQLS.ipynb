{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import (List, Tuple)\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane import PauliX, PauliY, PauliZ\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from vqls import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we set the main hyper-parameters of the model\n",
    "\n",
    "# Main variable parameters\n",
    "n_qubits = 4\n",
    "steps = 2000\n",
    "eta = 0.99\n",
    "layers = 2\n",
    "q_delta = 0.001\n",
    "err_tol = 10**-8\n",
    "\n",
    "# These parameters affect the Ising model system\n",
    "# Fixed in paper\n",
    "J = 0.1\n",
    "# Need to choose correct values\n",
    "zeta = 8.1\n",
    "eta_ising = 4.1\n",
    "\n",
    "\n",
    "n_shots = 10**7\n",
    "tot_qubits = n_qubits + 1\n",
    "ancilla_idx = n_qubits\n",
    "\n",
    "# Works for simplified 2-design (odd or even number of qubits)\n",
    "n_parameters = n_qubits + layers*(2*n_qubits - 2)\n",
    "rng_seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ─╭SimplifiedTwoDesign─┤  \n",
      "1: ─├SimplifiedTwoDesign─┤  \n",
      "2: ─├SimplifiedTwoDesign─┤  \n",
      "3: ─╰SimplifiedTwoDesign─┤  \n"
     ]
    }
   ],
   "source": [
    "init_weights, weights, w = generate_weights(n_qubits, layers, q_delta)\n",
    "\n",
    "def variational_block(init_weights, weights):\n",
    "    #for idx in range(n_qubits):\n",
    "    #    qml.Hadamard(wires=idx)\n",
    "    qml.templates.SimplifiedTwoDesign(initial_layer_weights=init_weights, weights=weights, wires=range(n_qubits))\n",
    "\n",
    "drawer = qml.draw(variational_block)\n",
    "print(drawer(init_weights=init_weights, weights=weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0009261\n",
      "[0.01141955+0.j 0.23862471+0.j 0.25138402+0.j 0.26662201+0.j\n",
      " 0.27855405+0.j 0.47858915+0.j 0.49382716+0.j 0.50575918+0.j\n",
      " 0.50658649+0.j 0.51851851+0.j 0.53375649+0.j 0.73379165+0.j\n",
      " 0.74572366+0.j 0.76096165+0.j 0.77372098+0.j 1.00092614+0.j]\n",
      "2.252277\n",
      "[[0.54270715 0.12334256 0.12334256 0.         0.12334256 0.\n",
      "  0.         0.         0.12334256 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.12334256 0.51803869 0.         0.12334256 0.         0.12334256\n",
      "  0.         0.         0.         0.12334256 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.12334256 0.         0.49337021 0.12334256 0.         0.\n",
      "  0.12334256 0.         0.         0.         0.12334256 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.12334256 0.12334256 0.51803869 0.         0.\n",
      "  0.         0.12334256 0.         0.         0.         0.12334256\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.12334256 0.         0.         0.         0.49337021 0.12334256\n",
      "  0.12334256 0.         0.         0.         0.         0.\n",
      "  0.12334256 0.         0.         0.        ]\n",
      " [0.         0.12334256 0.         0.         0.12334256 0.46870169\n",
      "  0.         0.12334256 0.         0.         0.         0.\n",
      "  0.         0.12334256 0.         0.        ]\n",
      " [0.         0.         0.12334256 0.         0.12334256 0.\n",
      "  0.49337021 0.12334256 0.         0.         0.         0.\n",
      "  0.         0.         0.12334256 0.        ]\n",
      " [0.         0.         0.         0.12334256 0.         0.12334256\n",
      "  0.12334256 0.51803869 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.12334256]\n",
      " [0.12334256 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.51803869 0.12334256 0.12334256 0.\n",
      "  0.12334256 0.         0.         0.        ]\n",
      " [0.         0.12334256 0.         0.         0.         0.\n",
      "  0.         0.         0.12334256 0.49337021 0.         0.12334256\n",
      "  0.         0.12334256 0.         0.        ]\n",
      " [0.         0.         0.12334256 0.         0.         0.\n",
      "  0.         0.         0.12334256 0.         0.46870169 0.12334256\n",
      "  0.         0.         0.12334256 0.        ]\n",
      " [0.         0.         0.         0.12334256 0.         0.\n",
      "  0.         0.         0.         0.12334256 0.12334256 0.49337021\n",
      "  0.         0.         0.         0.12334256]\n",
      " [0.         0.         0.         0.         0.12334256 0.\n",
      "  0.         0.         0.12334256 0.         0.         0.\n",
      "  0.51803869 0.12334256 0.12334256 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.12334256\n",
      "  0.         0.         0.         0.12334256 0.         0.\n",
      "  0.12334256 0.49337021 0.         0.12334256]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.12334256 0.         0.         0.         0.12334256 0.\n",
      "  0.12334256 0.         0.51803869 0.12334256]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12334256 0.         0.         0.         0.12334256\n",
      "  0.         0.12334256 0.12334256 0.54270715]]\n",
      "198.59256\n"
     ]
    }
   ],
   "source": [
    "# Coefficients of the linear combination A = c_0 A_0 + c_1 A_1 ...\n",
    "'''\n",
    "c = np.array([1.0, 0.2, 0.2])\n",
    "\n",
    "A_terms = [\"III\", \"XZI\", \"XII\"]\n",
    "A_mat = A_to_num(n_qubits, c, A_terms)\n",
    "A_norm = np.linalg.norm(A_mat)\n",
    "print(A_norm)\n",
    "\n",
    "c = c / A_norm\n",
    "norm_A_mat = A_to_num(n_qubits, c, A_terms)\n",
    "\n",
    "\n",
    "print(np.linalg.norm(norm_A_mat))\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "c, A_terms = A_Ising_num(n_qubits, zeta, eta_ising, J)\n",
    "\n",
    "A_mat = A_to_num(n_qubits, c, A_terms)\n",
    "print(np.linalg.norm(A_mat, ord = 2))\n",
    "print(np.sort(np.linalg.eigvals(A_mat)))\n",
    "\n",
    "A_norm = np.linalg.norm(A_mat, ord = 2)\n",
    "c = np.array(c)\n",
    "c /= A_norm\n",
    "\n",
    "norm_A_mat = A_to_num(n_qubits, c, A_terms)\n",
    "print(np.linalg.norm(norm_A_mat))\n",
    "        \n",
    "'''\n",
    "def variational_block(weights):\n",
    "    #Variational circuit mapping the ground state |0> to the ansatz state |x>.\n",
    "    \n",
    "    #for idx in range(n_qubits):\n",
    "    #    qml.Hadamard(wires=idx)\n",
    "\n",
    "    for idx, element in enumerate(weights):\n",
    "        if idx > 3:\n",
    "            break\n",
    "        qml.RY(element, wires=idx)\n",
    "\n",
    "    #\n",
    "    qml.CZ(wires=(0, 1))\n",
    "    qml.CZ(wires=(2, 3))\n",
    "\n",
    "    for idx, element in enumerate(weights):\n",
    "        if idx <= 3:\n",
    "            continue\n",
    "        if idx > 7:\n",
    "            break\n",
    "        qml.RY(element, wires=idx%4)\n",
    "        \n",
    "    qml.CZ(wires=(1, 2))\n",
    "    \n",
    "    for idx, element in enumerate(weights):\n",
    "        if idx <= 7:\n",
    "            continue\n",
    "        if idx == 8:\n",
    "            continue\n",
    "        if idx == 11:\n",
    "            continue\n",
    "        if idx > 11:\n",
    "            break\n",
    "        qml.RY(element, wires = idx%4)\n",
    "\n",
    "    \n",
    "    #\n",
    "    qml.CZ(wires=(0, 1))\n",
    "    qml.CZ(wires=(2, 3))\n",
    "\n",
    "    for idx, element in enumerate(weights):\n",
    "        if idx <= 11:\n",
    "            continue\n",
    "        if idx > 15:\n",
    "            break\n",
    "        qml.RY(element, wires=idx%4)\n",
    "\n",
    "    qml.CZ(wires=(1, 2))\n",
    "\n",
    "    for idx, element in enumerate(weights):\n",
    "        if idx <= 15:\n",
    "            continue\n",
    "        if ((idx == 16) or (idx == 19)):\n",
    "            continue\n",
    "        if idx > 19:\n",
    "            break\n",
    "        qml.RY(element, wires = idx%4)\n",
    "    \n",
    "        \n",
    "    \n",
    "    #\n",
    "    qml.CZ(wires=(0, 1))\n",
    "    qml.CZ(wires=(2, 3))\n",
    "\n",
    "    for idx, element in enumerate(weights):\n",
    "        if idx <= 19:\n",
    "            continue\n",
    "        if idx > 23:\n",
    "            break\n",
    "        qml.RY(element, wires=idx%4)\n",
    "\n",
    "    qml.CZ(wires=(1, 2))\n",
    "\n",
    "    for idx, element in enumerate(weights):\n",
    "        if idx <= 23:\n",
    "            continue\n",
    "        if ((idx == 24) or (idx == 27)):\n",
    "            continue\n",
    "        if idx > 27:\n",
    "            break\n",
    "        qml.RY(element, wires = idx%4)\n",
    "    \n",
    "\n",
    "\n",
    "    #\n",
    "    qml.CZ(wires=(0, 1))\n",
    "    qml.CZ(wires=(2, 3))\n",
    "\n",
    "    for idx, element in enumerate(weights):\n",
    "        if idx <= 27:\n",
    "            continue\n",
    "        if idx > 31:\n",
    "            break\n",
    "        qml.RY(element, wires=idx%4)\n",
    "\n",
    "    qml.CZ(wires=(1, 2))\n",
    "\n",
    "    for idx, element in enumerate(weights):\n",
    "        if idx <= 31:\n",
    "            continue\n",
    "        if ((idx == 32) or (idx == 35)):\n",
    "            continue\n",
    "        if idx > 35:\n",
    "            break\n",
    "        qml.RY(element, wires = idx%4)\n",
    "\n",
    "\n",
    "    #\n",
    "    qml.CZ(wires=(0, 1))\n",
    "    qml.CZ(wires=(2, 3))\n",
    "\n",
    "    for idx, element in enumerate(weights):\n",
    "        if idx <= 35:\n",
    "            continue\n",
    "        if idx > 39:\n",
    "            break\n",
    "        qml.RY(element, wires=idx%4)\n",
    "\n",
    "    qml.CZ(wires=(1, 2))\n",
    "\n",
    "    for idx, element in enumerate(weights):\n",
    "        if idx <= 39:\n",
    "            continue\n",
    "        if ((idx == 40) or (idx == 43)):\n",
    "            continue\n",
    "        if idx > 43:\n",
    "            break\n",
    "        qml.RY(element, wires = idx%4)\n",
    "\n",
    "        #\n",
    "    qml.CZ(wires=(0, 1))\n",
    "    qml.CZ(wires=(2, 3))\n",
    "\n",
    "    for idx, element in enumerate(weights):\n",
    "        if idx <= 43:\n",
    "            continue\n",
    "        if idx > 47:\n",
    "            break\n",
    "        qml.RY(element, wires=idx%4)\n",
    "\n",
    "    qml.CZ(wires=(1, 2))\n",
    "\n",
    "    for idx, element in enumerate(weights):\n",
    "        if idx <= 47:\n",
    "            continue\n",
    "        if ((idx == 48) or (idx == 51)):\n",
    "            continue\n",
    "        if idx > 51:\n",
    "            break\n",
    "        qml.RY(element, wires = idx%4)\n",
    "\n",
    "    #\n",
    "    \n",
    "    qml.CZ(wires=(0, 1))\n",
    "    qml.CZ(wires=(2, 3))\n",
    "\n",
    "    for idx, element in enumerate(weights):\n",
    "        if idx <= 51:\n",
    "            continue\n",
    "        if idx > 55:\n",
    "            break\n",
    "        qml.RY(element, wires=idx%4)\n",
    "\n",
    "    qml.CZ(wires=(1, 2))\n",
    "\n",
    "    for idx, element in enumerate(weights):\n",
    "        if idx <= 55:\n",
    "            continue\n",
    "        if ((idx == 56) or (idx == 59)):\n",
    "            continue\n",
    "        if idx > 59:\n",
    "            break\n",
    "        qml.RY(element, wires = idx%4)\n",
    "    \n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def U_b():\n",
    "    \"\"\"Unitary matrix rotating the ground state to the problem vector |b> = U_b |0>.\"\"\"\n",
    "    for idx in range(n_qubits):\n",
    "        qml.Hadamard(wires=idx)\n",
    "\n",
    "\n",
    "'''\n",
    "np.random.seed(rng_seed)\n",
    "#w = q_delta * np.random.randn(7*n_qubits, requires_grad=True)\n",
    "w = range(15*n_qubits)\n",
    "\n",
    "drawer = qml.draw(variational_block)\n",
    "print(drawer(w))\n",
    "'''\n",
    "A_num = A_to_num(n_qubits, c, A_terms)\n",
    "print(np.real(A_num))\n",
    "\n",
    "condition_number = np.linalg.norm(A_num) * np.linalg.norm(np.linalg.inv(A_num))\n",
    "print(condition_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_mu = qml.device(\"default.qubit\", wires=tot_qubits)\n",
    "\n",
    "@qml.qnode(dev_mu, interface=\"autograd\")\n",
    "def local_hadamard_test(init_weights, weights, l=None, lp=None, j=None, part=None):\n",
    "\n",
    "    \n",
    "    # First Hadamard gate applied to the ancillary qubit.\n",
    "    qml.Hadamard(wires=ancilla_idx)\n",
    "\n",
    "    # For estimating the imaginary part of the coefficient \"mu\", we must add a \"-i\"\n",
    "    # phase gate.\n",
    "    if part == \"Im\" or part == \"im\":\n",
    "        qml.PhaseShift(-np.pi / 2, wires=ancilla_idx)\n",
    "\n",
    "    # Variational circuit generating a guess for the solution vector |x>\n",
    "    variational_block(init_weights, weights)\n",
    "\n",
    "    # Controlled application of the unitary component A_l of the problem matrix A.\n",
    "    A_to_code(idx = l, ancilla_idx= ancilla_idx, terms = A_terms)\n",
    "\n",
    "    # Adjoint of the unitary U_b associated to the problem vector |b>.\n",
    "    # In this specific example Adjoint(U_b) = U_b.\n",
    "    U_b()\n",
    "\n",
    "    # Controlled Z operator at position j. If j = -1, apply the identity.\n",
    "    if j != -1:\n",
    "        qml.CZ(wires=[ancilla_idx, j])\n",
    "\n",
    "    # Unitary U_b associated to the problem vector |b>.\n",
    "    U_b()\n",
    "\n",
    "    # Controlled application of Adjoint(A_lp).\n",
    "    # In this specific example Adjoint(A_lp) = A_lp.\n",
    "    A_to_code(idx= lp, ancilla_idx= ancilla_idx, terms= A_terms)\n",
    "\n",
    "    # Second Hadamard gate applied to the ancillary qubit.\n",
    "    qml.Hadamard(wires=ancilla_idx)\n",
    "\n",
    "    # Expectation value of Z for the ancillary qubit.\n",
    "    return qml.expval(qml.PauliZ(wires=ancilla_idx))\n",
    "\n",
    "def mu(init_weights, weights, l=None, lp=None, j=None):\n",
    "    \"\"\"Generates the coefficients to compute the \"local\" cost function C_L.\"\"\"\n",
    "\n",
    "    mu_real = local_hadamard_test(init_weights, weights, l=l, lp=lp, j=j, part=\"Re\")\n",
    "    mu_imag = local_hadamard_test(init_weights, weights, l=l, lp=lp, j=j, part=\"Im\")\n",
    "\n",
    "    return mu_real + 1.0j * mu_imag\n",
    "\n",
    "def psi_norm(init_weights, weights):\n",
    "    \"\"\"Returns the normalization constant <psi|psi>, where |psi> = A |x>.\"\"\"\n",
    "    norm = 0.0\n",
    "\n",
    "    for l in range(0, len(c)):\n",
    "        for lp in range(0, len(c)):\n",
    "            norm = norm + c[l] * np.conj(c[lp]) * mu(init_weights, weights, l, lp, -1)\n",
    "\n",
    "    return abs(norm)\n",
    "\n",
    "\n",
    "def cost_loc(w):\n",
    "    init_weights, weights = reshape_weights(n_qubits, n_parameters, layers, w)\n",
    "\n",
    "    \"\"\"Local version of the cost function. Tends to zero when A|x> is proportional to |b>.\"\"\"\n",
    "    mu_sum = 0.0\n",
    "\n",
    "    for l in range(0, len(c)):\n",
    "        for lp in range(0, len(c)):\n",
    "            for j in range(0, n_qubits):\n",
    "                mu_sum = mu_sum + c[l] * np.conj(c[lp]) * mu(init_weights, weights, l, lp, j)\n",
    "\n",
    "    mu_sum = abs(mu_sum)\n",
    "\n",
    "    # Cost function C_L\n",
    "    return 0.5 - 0.5 * mu_sum / (n_qubits * psi_norm(init_weights, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   0       Cost_L = 0.311041947\n",
      "Step   1       Cost_L = 0.220026853\n",
      "Step   2       Cost_L = 0.162762837\n",
      "Step   3       Cost_L = 0.121631267\n",
      "Step   4       Cost_L = 0.091540780\n",
      "Step   5       Cost_L = 0.069745001\n",
      "Step   6       Cost_L = 0.054140345\n",
      "Step   7       Cost_L = 0.042996686\n",
      "Step   8       Cost_L = 0.034958226\n",
      "Step   9       Cost_L = 0.029036729\n",
      "Step  10       Cost_L = 0.024554136\n",
      "Step  11       Cost_L = 0.021062383\n",
      "Step  12       Cost_L = 0.018269595\n",
      "Step  13       Cost_L = 0.015984704\n",
      "Step  14       Cost_L = 0.014080326\n",
      "Step  15       Cost_L = 0.012469294\n",
      "Step  16       Cost_L = 0.011090193\n",
      "Step  17       Cost_L = 0.009898458\n",
      "Step  18       Cost_L = 0.008860842\n",
      "Step  19       Cost_L = 0.007951905\n",
      "Step  20       Cost_L = 0.007151737\n",
      "Step  21       Cost_L = 0.006444444\n",
      "Step  22       Cost_L = 0.005817120\n",
      "Step  23       Cost_L = 0.005259127\n",
      "Step  24       Cost_L = 0.004761588\n",
      "Step  25       Cost_L = 0.004317014\n",
      "Step  26       Cost_L = 0.003919029\n",
      "Step  27       Cost_L = 0.003562165\n",
      "Step  28       Cost_L = 0.003241702\n",
      "Step  29       Cost_L = 0.002953541\n",
      "Step  30       Cost_L = 0.002694110\n",
      "Step  31       Cost_L = 0.002460279\n",
      "Step  32       Cost_L = 0.002249300\n",
      "Step  33       Cost_L = 0.002058752\n",
      "Step  34       Cost_L = 0.001886496\n",
      "Step  35       Cost_L = 0.001730636\n",
      "Step  36       Cost_L = 0.001589494\n",
      "Step  37       Cost_L = 0.001461573\n",
      "Step  38       Cost_L = 0.001345546\n",
      "Step  39       Cost_L = 0.001240226\n",
      "Step  40       Cost_L = 0.001144553\n",
      "Step  41       Cost_L = 0.001057582\n",
      "Step  42       Cost_L = 0.000978465\n",
      "Step  43       Cost_L = 0.000906442\n",
      "Step  44       Cost_L = 0.000840833\n",
      "Step  45       Cost_L = 0.000781025\n",
      "Step  46       Cost_L = 0.000726470\n",
      "Step  47       Cost_L = 0.000676672\n",
      "Step  48       Cost_L = 0.000631186\n",
      "Step  49       Cost_L = 0.000589613\n",
      "Step  50       Cost_L = 0.000551589\n",
      "Step  51       Cost_L = 0.000516790\n",
      "Step  52       Cost_L = 0.000484920\n",
      "Step  53       Cost_L = 0.000455714\n",
      "Step  54       Cost_L = 0.000428931\n",
      "Step  55       Cost_L = 0.000404353\n",
      "Step  56       Cost_L = 0.000381784\n",
      "Step  57       Cost_L = 0.000361045\n",
      "Step  58       Cost_L = 0.000341976\n",
      "Step  59       Cost_L = 0.000324428\n",
      "Step  60       Cost_L = 0.000308271\n",
      "Step  61       Cost_L = 0.000293382\n",
      "Step  62       Cost_L = 0.000279652\n",
      "Step  63       Cost_L = 0.000266983\n",
      "Step  64       Cost_L = 0.000255282\n",
      "Step  65       Cost_L = 0.000244470\n",
      "Step  66       Cost_L = 0.000234469\n",
      "Step  67       Cost_L = 0.000225213\n",
      "Step  68       Cost_L = 0.000216639\n",
      "Step  69       Cost_L = 0.000208691\n",
      "Step  70       Cost_L = 0.000201317\n",
      "Step  71       Cost_L = 0.000194470\n",
      "Step  72       Cost_L = 0.000188107\n",
      "Step  73       Cost_L = 0.000182189\n",
      "Step  74       Cost_L = 0.000176681\n",
      "Step  75       Cost_L = 0.000171549\n",
      "Step  76       Cost_L = 0.000166764\n",
      "Step  77       Cost_L = 0.000162297\n",
      "Step  78       Cost_L = 0.000158125\n",
      "Step  79       Cost_L = 0.000154225\n",
      "Step  80       Cost_L = 0.000150574\n",
      "Step  81       Cost_L = 0.000147155\n",
      "Step  82       Cost_L = 0.000143949\n",
      "Step  83       Cost_L = 0.000140940\n",
      "Step  84       Cost_L = 0.000138113\n",
      "Step  85       Cost_L = 0.000135455\n",
      "Step  86       Cost_L = 0.000132953\n",
      "Step  87       Cost_L = 0.000130596\n",
      "Step  88       Cost_L = 0.000128372\n",
      "Step  89       Cost_L = 0.000126273\n",
      "Step  90       Cost_L = 0.000124289\n",
      "Step  91       Cost_L = 0.000122411\n",
      "Step  92       Cost_L = 0.000120633\n",
      "Step  93       Cost_L = 0.000118947\n",
      "Step  94       Cost_L = 0.000117347\n",
      "Step  95       Cost_L = 0.000115827\n",
      "Step  96       Cost_L = 0.000114381\n",
      "Step  97       Cost_L = 0.000113004\n",
      "Step  98       Cost_L = 0.000111692\n",
      "Step  99       Cost_L = 0.000110439\n",
      "Step 100       Cost_L = 0.000109243\n",
      "Step 101       Cost_L = 0.000108099\n",
      "Step 102       Cost_L = 0.000107003\n",
      "Step 103       Cost_L = 0.000105954\n",
      "Step 104       Cost_L = 0.000104947\n",
      "Step 105       Cost_L = 0.000103979\n",
      "Step 106       Cost_L = 0.000103050\n",
      "Step 107       Cost_L = 0.000102155\n",
      "Step 108       Cost_L = 0.000101293\n",
      "Step 109       Cost_L = 0.000100461\n",
      "Step 110       Cost_L = 0.000099659\n",
      "Step 111       Cost_L = 0.000098883\n",
      "Step 112       Cost_L = 0.000098133\n",
      "Step 113       Cost_L = 0.000097407\n",
      "Step 114       Cost_L = 0.000096703\n",
      "Step 115       Cost_L = 0.000096021\n",
      "Step 116       Cost_L = 0.000095358\n",
      "Step 117       Cost_L = 0.000094714\n",
      "Step 118       Cost_L = 0.000094088\n",
      "Step 119       Cost_L = 0.000093478\n",
      "Step 120       Cost_L = 0.000092884\n",
      "Step 121       Cost_L = 0.000092305\n",
      "Step 122       Cost_L = 0.000091740\n",
      "Step 123       Cost_L = 0.000091189\n",
      "Step 124       Cost_L = 0.000090650\n",
      "Step 125       Cost_L = 0.000090123\n",
      "Step 126       Cost_L = 0.000089607\n",
      "Step 127       Cost_L = 0.000089102\n",
      "Step 128       Cost_L = 0.000088607\n",
      "Step 129       Cost_L = 0.000088121\n",
      "Step 130       Cost_L = 0.000087645\n",
      "Step 131       Cost_L = 0.000087178\n",
      "Step 132       Cost_L = 0.000086719\n",
      "Step 133       Cost_L = 0.000086267\n",
      "Step 134       Cost_L = 0.000085824\n",
      "Step 135       Cost_L = 0.000085387\n",
      "Step 136       Cost_L = 0.000084958\n",
      "Step 137       Cost_L = 0.000084535\n",
      "Step 138       Cost_L = 0.000084118\n",
      "Step 139       Cost_L = 0.000083707\n",
      "Step 140       Cost_L = 0.000083302\n",
      "Step 141       Cost_L = 0.000082902\n",
      "Step 142       Cost_L = 0.000082508\n",
      "Step 143       Cost_L = 0.000082119\n",
      "Step 144       Cost_L = 0.000081735\n",
      "Step 145       Cost_L = 0.000081355\n",
      "Step 146       Cost_L = 0.000080980\n",
      "Step 147       Cost_L = 0.000080609\n",
      "Step 148       Cost_L = 0.000080242\n",
      "Step 149       Cost_L = 0.000079880\n",
      "Step 150       Cost_L = 0.000079521\n",
      "Step 151       Cost_L = 0.000079166\n",
      "Step 152       Cost_L = 0.000078814\n",
      "Step 153       Cost_L = 0.000078467\n",
      "Step 154       Cost_L = 0.000078122\n",
      "Step 155       Cost_L = 0.000077781\n",
      "Step 156       Cost_L = 0.000077443\n",
      "Step 157       Cost_L = 0.000077108\n",
      "Step 158       Cost_L = 0.000076776\n",
      "Step 159       Cost_L = 0.000076447\n",
      "Step 160       Cost_L = 0.000076121\n",
      "Step 161       Cost_L = 0.000075797\n",
      "Step 162       Cost_L = 0.000075477\n",
      "Step 163       Cost_L = 0.000075158\n",
      "Step 164       Cost_L = 0.000074843\n",
      "Step 165       Cost_L = 0.000074530\n",
      "Step 166       Cost_L = 0.000074219\n",
      "Step 167       Cost_L = 0.000073911\n",
      "Step 168       Cost_L = 0.000073605\n",
      "Step 169       Cost_L = 0.000073301\n",
      "Step 170       Cost_L = 0.000073000\n",
      "Step 171       Cost_L = 0.000072700\n",
      "Step 172       Cost_L = 0.000072403\n",
      "Step 173       Cost_L = 0.000072108\n",
      "Step 174       Cost_L = 0.000071815\n",
      "Step 175       Cost_L = 0.000071524\n",
      "Step 176       Cost_L = 0.000071235\n",
      "Step 177       Cost_L = 0.000070947\n",
      "Step 178       Cost_L = 0.000070662\n",
      "Step 179       Cost_L = 0.000070379\n",
      "Step 180       Cost_L = 0.000070097\n",
      "Step 181       Cost_L = 0.000069817\n",
      "Step 182       Cost_L = 0.000069539\n",
      "Step 183       Cost_L = 0.000069263\n",
      "Step 184       Cost_L = 0.000068988\n",
      "Step 185       Cost_L = 0.000068716\n",
      "Step 186       Cost_L = 0.000068444\n",
      "Step 187       Cost_L = 0.000068175\n",
      "Step 188       Cost_L = 0.000067907\n",
      "Step 189       Cost_L = 0.000067641\n",
      "Step 190       Cost_L = 0.000067376\n",
      "Step 191       Cost_L = 0.000067113\n",
      "Step 192       Cost_L = 0.000066851\n",
      "Step 193       Cost_L = 0.000066591\n",
      "Step 194       Cost_L = 0.000066332\n",
      "Step 195       Cost_L = 0.000066075\n",
      "Step 196       Cost_L = 0.000065819\n",
      "Step 197       Cost_L = 0.000065565\n",
      "Step 198       Cost_L = 0.000065312\n",
      "Step 199       Cost_L = 0.000065061\n",
      "Step 200       Cost_L = 0.000064811\n",
      "Step 201       Cost_L = 0.000064562\n",
      "Step 202       Cost_L = 0.000064315\n",
      "Step 203       Cost_L = 0.000064069\n",
      "Step 204       Cost_L = 0.000063825\n",
      "Step 205       Cost_L = 0.000063582\n",
      "Step 206       Cost_L = 0.000063340\n",
      "Step 207       Cost_L = 0.000063099\n",
      "Step 208       Cost_L = 0.000062860\n",
      "Step 209       Cost_L = 0.000062622\n",
      "Step 210       Cost_L = 0.000062385\n",
      "Step 211       Cost_L = 0.000062150\n",
      "Step 212       Cost_L = 0.000061916\n",
      "Step 213       Cost_L = 0.000061683\n",
      "Step 214       Cost_L = 0.000061451\n",
      "Step 215       Cost_L = 0.000061221\n",
      "Step 216       Cost_L = 0.000060991\n",
      "Step 217       Cost_L = 0.000060763\n",
      "Step 218       Cost_L = 0.000060537\n",
      "Step 219       Cost_L = 0.000060311\n",
      "Step 220       Cost_L = 0.000060086\n",
      "Step 221       Cost_L = 0.000059863\n",
      "Step 222       Cost_L = 0.000059641\n",
      "Step 223       Cost_L = 0.000059419\n",
      "Step 224       Cost_L = 0.000059200\n",
      "Step 225       Cost_L = 0.000058981\n",
      "Step 226       Cost_L = 0.000058763\n",
      "Step 227       Cost_L = 0.000058546\n",
      "Step 228       Cost_L = 0.000058331\n",
      "Step 229       Cost_L = 0.000058116\n",
      "Step 230       Cost_L = 0.000057903\n",
      "Step 231       Cost_L = 0.000057691\n",
      "Step 232       Cost_L = 0.000057479\n",
      "Step 233       Cost_L = 0.000057269\n",
      "Step 234       Cost_L = 0.000057060\n",
      "Step 235       Cost_L = 0.000056852\n",
      "Step 236       Cost_L = 0.000056645\n",
      "Step 237       Cost_L = 0.000056439\n",
      "Step 238       Cost_L = 0.000056234\n",
      "Step 239       Cost_L = 0.000056030\n",
      "Step 240       Cost_L = 0.000055827\n",
      "Step 241       Cost_L = 0.000055625\n",
      "Step 242       Cost_L = 0.000055424\n",
      "Step 243       Cost_L = 0.000055224\n",
      "Step 244       Cost_L = 0.000055025\n",
      "Step 245       Cost_L = 0.000054827\n",
      "Step 246       Cost_L = 0.000054630\n",
      "Step 247       Cost_L = 0.000054434\n",
      "Step 248       Cost_L = 0.000054239\n",
      "Step 249       Cost_L = 0.000054044\n",
      "Step 250       Cost_L = 0.000053851\n",
      "Step 251       Cost_L = 0.000053659\n",
      "Step 252       Cost_L = 0.000053467\n",
      "Step 253       Cost_L = 0.000053277\n",
      "Step 254       Cost_L = 0.000053087\n",
      "Step 255       Cost_L = 0.000052899\n",
      "Step 256       Cost_L = 0.000052711\n",
      "Step 257       Cost_L = 0.000052524\n",
      "Step 258       Cost_L = 0.000052338\n",
      "Step 259       Cost_L = 0.000052153\n",
      "Step 260       Cost_L = 0.000051969\n",
      "Step 261       Cost_L = 0.000051786\n",
      "Step 262       Cost_L = 0.000051603\n",
      "Step 263       Cost_L = 0.000051422\n",
      "Step 264       Cost_L = 0.000051241\n",
      "Step 265       Cost_L = 0.000051061\n",
      "Step 266       Cost_L = 0.000050882\n",
      "Step 267       Cost_L = 0.000050704\n",
      "Step 268       Cost_L = 0.000050526\n",
      "Step 269       Cost_L = 0.000050350\n",
      "Step 270       Cost_L = 0.000050174\n",
      "Step 271       Cost_L = 0.000049999\n",
      "Step 272       Cost_L = 0.000049825\n",
      "Step 273       Cost_L = 0.000049652\n",
      "Step 274       Cost_L = 0.000049480\n",
      "Step 275       Cost_L = 0.000049308\n",
      "Step 276       Cost_L = 0.000049137\n",
      "Step 277       Cost_L = 0.000048967\n",
      "Step 278       Cost_L = 0.000048798\n",
      "Step 279       Cost_L = 0.000048630\n",
      "Step 280       Cost_L = 0.000048462\n",
      "Step 281       Cost_L = 0.000048295\n",
      "Step 282       Cost_L = 0.000048129\n",
      "Step 283       Cost_L = 0.000047964\n",
      "Step 284       Cost_L = 0.000047799\n",
      "Step 285       Cost_L = 0.000047635\n",
      "Step 286       Cost_L = 0.000047472\n",
      "Step 287       Cost_L = 0.000047310\n",
      "Step 288       Cost_L = 0.000047148\n",
      "Step 289       Cost_L = 0.000046987\n",
      "Step 290       Cost_L = 0.000046827\n",
      "Step 291       Cost_L = 0.000046668\n",
      "Step 292       Cost_L = 0.000046509\n",
      "Step 293       Cost_L = 0.000046351\n",
      "Step 294       Cost_L = 0.000046194\n",
      "Step 295       Cost_L = 0.000046037\n",
      "Step 296       Cost_L = 0.000045882\n",
      "Step 297       Cost_L = 0.000045727\n",
      "Step 298       Cost_L = 0.000045572\n",
      "Step 299       Cost_L = 0.000045418\n",
      "Step 300       Cost_L = 0.000045265\n",
      "Step 301       Cost_L = 0.000045113\n",
      "Step 302       Cost_L = 0.000044961\n",
      "Step 303       Cost_L = 0.000044811\n",
      "Step 304       Cost_L = 0.000044660\n",
      "Step 305       Cost_L = 0.000044511\n",
      "Step 306       Cost_L = 0.000044362\n",
      "Step 307       Cost_L = 0.000044213\n",
      "Step 308       Cost_L = 0.000044066\n",
      "Step 309       Cost_L = 0.000043919\n",
      "Step 310       Cost_L = 0.000043772\n",
      "Step 311       Cost_L = 0.000043627\n",
      "Step 312       Cost_L = 0.000043482\n",
      "Step 313       Cost_L = 0.000043337\n",
      "Step 314       Cost_L = 0.000043194\n",
      "Step 315       Cost_L = 0.000043051\n",
      "Step 316       Cost_L = 0.000042908\n",
      "Step 317       Cost_L = 0.000042766\n",
      "Step 318       Cost_L = 0.000042625\n",
      "Step 319       Cost_L = 0.000042484\n",
      "Step 320       Cost_L = 0.000042344\n",
      "Step 321       Cost_L = 0.000042205\n",
      "Step 322       Cost_L = 0.000042066\n",
      "Step 323       Cost_L = 0.000041928\n",
      "Step 324       Cost_L = 0.000041791\n",
      "Step 325       Cost_L = 0.000041654\n",
      "Step 326       Cost_L = 0.000041517\n",
      "Step 327       Cost_L = 0.000041382\n",
      "Step 328       Cost_L = 0.000041246\n",
      "Step 329       Cost_L = 0.000041112\n",
      "Step 330       Cost_L = 0.000040978\n",
      "Step 331       Cost_L = 0.000040844\n",
      "Step 332       Cost_L = 0.000040711\n",
      "Step 333       Cost_L = 0.000040579\n",
      "Step 334       Cost_L = 0.000040447\n",
      "Step 335       Cost_L = 0.000040316\n",
      "Step 336       Cost_L = 0.000040186\n",
      "Step 337       Cost_L = 0.000040056\n",
      "Step 338       Cost_L = 0.000039926\n",
      "Step 339       Cost_L = 0.000039797\n",
      "Step 340       Cost_L = 0.000039669\n",
      "Step 341       Cost_L = 0.000039541\n",
      "Step 342       Cost_L = 0.000039414\n",
      "Step 343       Cost_L = 0.000039287\n",
      "Step 344       Cost_L = 0.000039161\n",
      "Step 345       Cost_L = 0.000039036\n",
      "Step 346       Cost_L = 0.000038910\n",
      "Step 347       Cost_L = 0.000038786\n",
      "Step 348       Cost_L = 0.000038662\n",
      "Step 349       Cost_L = 0.000038538\n",
      "Step 350       Cost_L = 0.000038415\n",
      "Step 351       Cost_L = 0.000038293\n",
      "Step 352       Cost_L = 0.000038171\n",
      "Step 353       Cost_L = 0.000038049\n",
      "Step 354       Cost_L = 0.000037928\n",
      "Step 355       Cost_L = 0.000037808\n",
      "Step 356       Cost_L = 0.000037688\n",
      "Step 357       Cost_L = 0.000037569\n",
      "Step 358       Cost_L = 0.000037450\n",
      "Step 359       Cost_L = 0.000037331\n",
      "Step 360       Cost_L = 0.000037213\n",
      "Step 361       Cost_L = 0.000037096\n",
      "Step 362       Cost_L = 0.000036979\n",
      "Step 363       Cost_L = 0.000036863\n",
      "Step 364       Cost_L = 0.000036747\n",
      "Step 365       Cost_L = 0.000036631\n",
      "Step 366       Cost_L = 0.000036516\n",
      "Step 367       Cost_L = 0.000036402\n",
      "Step 368       Cost_L = 0.000036288\n",
      "Step 369       Cost_L = 0.000036174\n",
      "Step 370       Cost_L = 0.000036061\n",
      "Step 371       Cost_L = 0.000035948\n",
      "Step 372       Cost_L = 0.000035836\n",
      "Step 373       Cost_L = 0.000035724\n",
      "Step 374       Cost_L = 0.000035613\n",
      "Step 375       Cost_L = 0.000035502\n",
      "Step 376       Cost_L = 0.000035392\n",
      "Step 377       Cost_L = 0.000035282\n",
      "Step 378       Cost_L = 0.000035173\n",
      "Step 379       Cost_L = 0.000035064\n",
      "Step 380       Cost_L = 0.000034955\n",
      "Step 381       Cost_L = 0.000034847\n",
      "Step 382       Cost_L = 0.000034739\n",
      "Step 383       Cost_L = 0.000034632\n",
      "Step 384       Cost_L = 0.000034525\n",
      "Step 385       Cost_L = 0.000034419\n",
      "Step 386       Cost_L = 0.000034313\n",
      "Step 387       Cost_L = 0.000034207\n",
      "Step 388       Cost_L = 0.000034102\n",
      "Step 389       Cost_L = 0.000033998\n",
      "Step 390       Cost_L = 0.000033894\n",
      "Step 391       Cost_L = 0.000033790\n",
      "Step 392       Cost_L = 0.000033686\n",
      "Step 393       Cost_L = 0.000033583\n",
      "Step 394       Cost_L = 0.000033481\n",
      "Step 395       Cost_L = 0.000033379\n",
      "Step 396       Cost_L = 0.000033277\n",
      "Step 397       Cost_L = 0.000033176\n",
      "Step 398       Cost_L = 0.000033075\n",
      "Step 399       Cost_L = 0.000032974\n",
      "Step 400       Cost_L = 0.000032874\n",
      "Step 401       Cost_L = 0.000032774\n",
      "Step 402       Cost_L = 0.000032675\n",
      "Step 403       Cost_L = 0.000032576\n",
      "Step 404       Cost_L = 0.000032478\n",
      "Step 405       Cost_L = 0.000032379\n",
      "Step 406       Cost_L = 0.000032282\n",
      "Step 407       Cost_L = 0.000032184\n",
      "Step 408       Cost_L = 0.000032087\n",
      "Step 409       Cost_L = 0.000031991\n",
      "Step 410       Cost_L = 0.000031895\n",
      "Step 411       Cost_L = 0.000031799\n",
      "Step 412       Cost_L = 0.000031703\n",
      "Step 413       Cost_L = 0.000031608\n",
      "Step 414       Cost_L = 0.000031514\n",
      "Step 415       Cost_L = 0.000031419\n",
      "Step 416       Cost_L = 0.000031325\n",
      "Step 417       Cost_L = 0.000031232\n",
      "Step 418       Cost_L = 0.000031138\n",
      "Step 419       Cost_L = 0.000031046\n",
      "Step 420       Cost_L = 0.000030953\n",
      "Step 421       Cost_L = 0.000030861\n",
      "Step 422       Cost_L = 0.000030769\n",
      "Step 423       Cost_L = 0.000030678\n",
      "Step 424       Cost_L = 0.000030587\n",
      "Step 425       Cost_L = 0.000030496\n",
      "Step 426       Cost_L = 0.000030406\n",
      "Step 427       Cost_L = 0.000030316\n",
      "Step 428       Cost_L = 0.000030226\n",
      "Step 429       Cost_L = 0.000030137\n",
      "Step 430       Cost_L = 0.000030048\n",
      "Step 431       Cost_L = 0.000029959\n",
      "Step 432       Cost_L = 0.000029871\n",
      "Step 433       Cost_L = 0.000029783\n",
      "Step 434       Cost_L = 0.000029695\n",
      "Step 435       Cost_L = 0.000029608\n",
      "Step 436       Cost_L = 0.000029521\n",
      "Step 437       Cost_L = 0.000029435\n",
      "Step 438       Cost_L = 0.000029348\n",
      "Step 439       Cost_L = 0.000029262\n",
      "Step 440       Cost_L = 0.000029177\n",
      "Step 441       Cost_L = 0.000029092\n",
      "Step 442       Cost_L = 0.000029007\n",
      "Step 443       Cost_L = 0.000028922\n",
      "Step 444       Cost_L = 0.000028838\n",
      "Step 445       Cost_L = 0.000028754\n",
      "Step 446       Cost_L = 0.000028670\n",
      "Step 447       Cost_L = 0.000028587\n",
      "Step 448       Cost_L = 0.000028504\n",
      "Step 449       Cost_L = 0.000028421\n",
      "Step 450       Cost_L = 0.000028339\n",
      "Step 451       Cost_L = 0.000028257\n",
      "Step 452       Cost_L = 0.000028175\n",
      "Step 453       Cost_L = 0.000028093\n",
      "Step 454       Cost_L = 0.000028012\n",
      "Step 455       Cost_L = 0.000027931\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m#cost_grad = qml.grad(cost_loc, argnum=0)(w)[0]\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m w, cost \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39;49mstep_and_cost(cost_loc, w)\n\u001b[0;32m     16\u001b[0m \u001b[39m#print(\"Step {:3d}       Cost_L = {:9.7f}        Cost_Grad = {:9.9f}\".format(it, cost, cost_grad))\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStep \u001b[39m\u001b[39m{:3d}\u001b[39;00m\u001b[39m       Cost_L = \u001b[39m\u001b[39m{:9.9f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(it, cost))\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\pennylane\\optimize\\gradient_descent.py:59\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.step_and_cost\u001b[1;34m(self, objective_fn, grad_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_and_cost\u001b[39m(\u001b[39mself\u001b[39m, objective_fn, \u001b[39m*\u001b[39margs, grad_fn\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     40\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Update trainable arguments with one step of the optimizer and return the corresponding\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39m    objective function value prior to the step.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39m        If single arg is provided, list [array] is replaced by array.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m     g, forward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_grad(objective_fn, args, kwargs, grad_fn\u001b[39m=\u001b[39;49mgrad_fn)\n\u001b[0;32m     60\u001b[0m     new_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_grad(g, args)\n\u001b[0;32m     62\u001b[0m     \u001b[39mif\u001b[39;00m forward \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\pennylane\\optimize\\gradient_descent.py:117\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.compute_grad\u001b[1;34m(objective_fn, args, kwargs, grad_fn)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Compute gradient of the objective function at the given point and return it along with\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[39mthe objective function forward pass (if available).\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39m    will not be evaluted and instead ``None`` will be returned.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m g \u001b[39m=\u001b[39m get_gradient(objective_fn) \u001b[39mif\u001b[39;00m grad_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m grad_fn\n\u001b[1;32m--> 117\u001b[0m grad \u001b[39m=\u001b[39m g(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    118\u001b[0m forward \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(g, \u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    120\u001b[0m num_trainable_args \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(\u001b[39mgetattr\u001b[39m(arg, \u001b[39m\"\u001b[39m\u001b[39mrequires_grad\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args)\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\pennylane\\_grad.py:117\u001b[0m, in \u001b[0;36mgrad.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fun(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    115\u001b[0m     \u001b[39mreturn\u001b[39;00m ()\n\u001b[1;32m--> 117\u001b[0m grad_value, ans \u001b[39m=\u001b[39m grad_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward \u001b[39m=\u001b[39m ans\n\u001b[0;32m    120\u001b[0m \u001b[39mreturn\u001b[39;00m grad_value\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\autograd\\wrap_util.py:20\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(args[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m argnum)\n\u001b[1;32m---> 20\u001b[0m \u001b[39mreturn\u001b[39;00m unary_operator(unary_f, x, \u001b[39m*\u001b[39;49mnary_op_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnary_op_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\pennylane\\_grad.py:135\u001b[0m, in \u001b[0;36mgrad._grad_with_forward\u001b[1;34m(fun, x)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[39m@unary_to_nary\u001b[39m\n\u001b[0;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_grad_with_forward\u001b[39m(fun, x):\n\u001b[0;32m    132\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"This function is a replica of ``autograd.grad``, with the only\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[39m    difference being that it returns both the gradient *and* the forward pass\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[39m    value.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m     vjp, ans \u001b[39m=\u001b[39m _make_vjp(fun, x)\n\u001b[0;32m    137\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m vspace(ans)\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    138\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    139\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mGrad only applies to real scalar-output functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTry jacobian, elementwise_grad or holomorphic_grad.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\autograd\\core.py:10\u001b[0m, in \u001b[0;36mmake_vjp\u001b[1;34m(fun, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_vjp\u001b[39m(fun, x):\n\u001b[0;32m      9\u001b[0m     start_node \u001b[39m=\u001b[39m VJPNode\u001b[39m.\u001b[39mnew_root()\n\u001b[1;32m---> 10\u001b[0m     end_value, end_node \u001b[39m=\u001b[39m  trace(start_node, fun, x)\n\u001b[0;32m     11\u001b[0m     \u001b[39mif\u001b[39;00m end_node \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m         \u001b[39mdef\u001b[39;00m \u001b[39mvjp\u001b[39m(g): \u001b[39mreturn\u001b[39;00m vspace(x)\u001b[39m.\u001b[39mzeros()\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\autograd\\tracer.py:10\u001b[0m, in \u001b[0;36mtrace\u001b[1;34m(start_node, fun, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mwith\u001b[39;00m trace_stack\u001b[39m.\u001b[39mnew_trace() \u001b[39mas\u001b[39;00m t:\n\u001b[0;32m      9\u001b[0m     start_box \u001b[39m=\u001b[39m new_box(x, t, start_node)\n\u001b[1;32m---> 10\u001b[0m     end_box \u001b[39m=\u001b[39m fun(start_box)\n\u001b[0;32m     11\u001b[0m     \u001b[39mif\u001b[39;00m isbox(end_box) \u001b[39mand\u001b[39;00m end_box\u001b[39m.\u001b[39m_trace \u001b[39m==\u001b[39m start_box\u001b[39m.\u001b[39m_trace:\n\u001b[0;32m     12\u001b[0m         \u001b[39mreturn\u001b[39;00m end_box\u001b[39m.\u001b[39m_value, end_box\u001b[39m.\u001b[39m_node\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\autograd\\wrap_util.py:15\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f.<locals>.unary_f\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     subargs \u001b[39m=\u001b[39m subvals(args, \u001b[39mzip\u001b[39m(argnum, x))\n\u001b[1;32m---> 15\u001b[0m \u001b[39mreturn\u001b[39;00m fun(\u001b[39m*\u001b[39;49msubargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "Cell \u001b[1;32mIn[5], line 70\u001b[0m, in \u001b[0;36mcost_loc\u001b[1;34m(w)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[39mfor\u001b[39;00m lp \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(c)):\n\u001b[0;32m     69\u001b[0m         \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, n_qubits):\n\u001b[1;32m---> 70\u001b[0m             mu_sum \u001b[39m=\u001b[39m mu_sum \u001b[39m+\u001b[39m c[l] \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mconj(c[lp]) \u001b[39m*\u001b[39m mu(init_weights, weights, l, lp, j)\n\u001b[0;32m     72\u001b[0m mu_sum \u001b[39m=\u001b[39m \u001b[39mabs\u001b[39m(mu_sum)\n\u001b[0;32m     74\u001b[0m \u001b[39m# Cost function C_L\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 46\u001b[0m, in \u001b[0;36mmu\u001b[1;34m(init_weights, weights, l, lp, j)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generates the coefficients to compute the \"local\" cost function C_L.\"\"\"\u001b[39;00m\n\u001b[0;32m     45\u001b[0m mu_real \u001b[39m=\u001b[39m local_hadamard_test(init_weights, weights, l\u001b[39m=\u001b[39ml, lp\u001b[39m=\u001b[39mlp, j\u001b[39m=\u001b[39mj, part\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRe\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m mu_imag \u001b[39m=\u001b[39m local_hadamard_test(init_weights, weights, l\u001b[39m=\u001b[39;49ml, lp\u001b[39m=\u001b[39;49mlp, j\u001b[39m=\u001b[39;49mj, part\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mIm\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     48\u001b[0m \u001b[39mreturn\u001b[39;00m mu_real \u001b[39m+\u001b[39m \u001b[39m1.0\u001b[39mj \u001b[39m*\u001b[39m mu_imag\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\pennylane\\qnode.py:867\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecute_kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    866\u001b[0m \u001b[39m# pylint: disable=unexpected-keyword-arg\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m res \u001b[39m=\u001b[39m qml\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    868\u001b[0m     [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtape],\n\u001b[0;32m    869\u001b[0m     device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice,\n\u001b[0;32m    870\u001b[0m     gradient_fn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_fn,\n\u001b[0;32m    871\u001b[0m     interface\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterface,\n\u001b[0;32m    872\u001b[0m     gradient_kwargs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_kwargs,\n\u001b[0;32m    873\u001b[0m     override_shots\u001b[39m=\u001b[39;49moverride_shots,\n\u001b[0;32m    874\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute_kwargs,\n\u001b[0;32m    875\u001b[0m )\n\u001b[0;32m    877\u001b[0m res \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m]\n\u001b[0;32m    879\u001b[0m \u001b[39mif\u001b[39;00m old_interface \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\pennylane\\interfaces\\execution.py:407\u001b[0m, in \u001b[0;36mexecute\u001b[1;34m(tapes, device, gradient_fn, interface, grad_on_execution, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion, device_batch_transform)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[39mreturn\u001b[39;00m batch_fn(res)\n\u001b[0;32m    405\u001b[0m \u001b[39mif\u001b[39;00m gradient_fn \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbackprop\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m interface \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    406\u001b[0m     \u001b[39mreturn\u001b[39;00m batch_fn(\n\u001b[1;32m--> 407\u001b[0m         qml\u001b[39m.\u001b[39;49minterfaces\u001b[39m.\u001b[39;49mcache_execute(\n\u001b[0;32m    408\u001b[0m             batch_execute, cache, return_tuple\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, expand_fn\u001b[39m=\u001b[39;49mexpand_fn\n\u001b[0;32m    409\u001b[0m         )(tapes)\n\u001b[0;32m    410\u001b[0m     )\n\u001b[0;32m    412\u001b[0m \u001b[39m# the default execution function is batch_execute\u001b[39;00m\n\u001b[0;32m    413\u001b[0m execute_fn \u001b[39m=\u001b[39m qml\u001b[39m.\u001b[39minterfaces\u001b[39m.\u001b[39mcache_execute(batch_execute, cache, expand_fn\u001b[39m=\u001b[39mexpand_fn)\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\pennylane\\interfaces\\execution.py:204\u001b[0m, in \u001b[0;36mcache_execute.<locals>.wrapper\u001b[1;34m(tapes, **kwargs)\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[39mreturn\u001b[39;00m (res, []) \u001b[39mif\u001b[39;00m return_tuple \u001b[39melse\u001b[39;00m res\n\u001b[0;32m    202\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[39m# execute all unique tapes that do not exist in the cache\u001b[39;00m\n\u001b[1;32m--> 204\u001b[0m     res \u001b[39m=\u001b[39m fn(execution_tapes\u001b[39m.\u001b[39;49mvalues(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    206\u001b[0m final_res \u001b[39m=\u001b[39m []\n\u001b[0;32m    208\u001b[0m \u001b[39mfor\u001b[39;00m i, tape \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tapes):\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\pennylane\\interfaces\\execution.py:130\u001b[0m, in \u001b[0;36mcache_execute.<locals>.fn\u001b[1;34m(tapes, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfn\u001b[39m(tapes: Sequence[QuantumTape], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):  \u001b[39m# pylint: disable=function-redefined\u001b[39;00m\n\u001b[0;32m    129\u001b[0m     tapes \u001b[39m=\u001b[39m [expand_fn(tape) \u001b[39mfor\u001b[39;00m tape \u001b[39min\u001b[39;00m tapes]\n\u001b[1;32m--> 130\u001b[0m     \u001b[39mreturn\u001b[39;00m original_fn(tapes, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[0;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[0;32m     80\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 81\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\pennylane\\_qubit_device.py:588\u001b[0m, in \u001b[0;36mQubitDevice.batch_execute\u001b[1;34m(self, circuits)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[39mfor\u001b[39;00m circuit \u001b[39min\u001b[39;00m circuits:\n\u001b[0;32m    584\u001b[0m     \u001b[39m# we need to reset the device here, else it will\u001b[39;00m\n\u001b[0;32m    585\u001b[0m     \u001b[39m# not start the next computation in the zero state\u001b[39;00m\n\u001b[0;32m    586\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset()\n\u001b[1;32m--> 588\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(circuit)\n\u001b[0;32m    589\u001b[0m     results\u001b[39m.\u001b[39mappend(res)\n\u001b[0;32m    591\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtracker\u001b[39m.\u001b[39mactive:\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\pennylane\\_qubit_device.py:318\u001b[0m, in \u001b[0;36mQubitDevice.execute\u001b[1;34m(self, circuit, **kwargs)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_validity(circuit\u001b[39m.\u001b[39moperations, circuit\u001b[39m.\u001b[39mobservables)\n\u001b[0;32m    317\u001b[0m \u001b[39m# apply all circuit operations\u001b[39;00m\n\u001b[1;32m--> 318\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(circuit\u001b[39m.\u001b[39;49moperations, rotations\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_diagonalizing_gates(circuit), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    320\u001b[0m \u001b[39m# generate computational basis samples\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshots \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m circuit\u001b[39m.\u001b[39mis_sampled:\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\pennylane\\devices\\default_qubit.py:276\u001b[0m, in \u001b[0;36mDefaultQubit.apply\u001b[1;34m(self, operations, rotations, **kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_parametrized_evolution(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state, operation)\n\u001b[0;32m    275\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 276\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply_operation(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_state, operation)\n\u001b[0;32m    278\u001b[0m \u001b[39m# store the pre-rotated state\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_rotated_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\pennylane\\devices\\default_qubit.py:316\u001b[0m, in \u001b[0;36mDefaultQubit._apply_operation\u001b[1;34m(self, state, operation)\u001b[0m\n\u001b[0;32m    313\u001b[0m     axes \u001b[39m=\u001b[39m [ax \u001b[39m+\u001b[39m shift \u001b[39mfor\u001b[39;00m ax \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwires\u001b[39m.\u001b[39mindices(wires)]\n\u001b[0;32m    314\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_ops[operation\u001b[39m.\u001b[39mbase_name](state, axes)\n\u001b[1;32m--> 316\u001b[0m matrix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_asarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_unitary_matrix(operation), dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC_DTYPE)\n\u001b[0;32m    318\u001b[0m \u001b[39mif\u001b[39;00m operation \u001b[39min\u001b[39;00m diagonal_in_z_basis:\n\u001b[0;32m    319\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_diagonal_unitary(state, matrix, wires)\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\pennylane\\devices\\default_qubit.py:647\u001b[0m, in \u001b[0;36mDefaultQubit._get_unitary_matrix\u001b[1;34m(self, unitary)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[39mif\u001b[39;00m unitary \u001b[39min\u001b[39;00m diagonal_in_z_basis:\n\u001b[0;32m    645\u001b[0m     \u001b[39mreturn\u001b[39;00m unitary\u001b[39m.\u001b[39meigvals()\n\u001b[1;32m--> 647\u001b[0m \u001b[39mreturn\u001b[39;00m unitary\u001b[39m.\u001b[39;49mmatrix()\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\pennylane\\operation.py:745\u001b[0m, in \u001b[0;36mOperator.matrix\u001b[1;34m(self, wire_order)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmatrix\u001b[39m(\u001b[39mself\u001b[39m, wire_order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    726\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Representation of the operator as a matrix in the computational basis.\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \n\u001b[0;32m    728\u001b[0m \u001b[39m    If ``wire_order`` is provided, the numerical representation considers the position of the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[39m        tensor_like: matrix representation\u001b[39;00m\n\u001b[0;32m    744\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     canonical_matrix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_matrix(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparameters, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhyperparameters)\n\u001b[0;32m    747\u001b[0m     \u001b[39mif\u001b[39;00m wire_order \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwires \u001b[39m==\u001b[39m Wires(wire_order):\n\u001b[0;32m    748\u001b[0m         \u001b[39mreturn\u001b[39;00m canonical_matrix\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\pennylane\\ops\\qubit\\parametric_ops_single_qubit.py:199\u001b[0m, in \u001b[0;36mRY.compute_matrix\u001b[1;34m(theta)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    177\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_matrix\u001b[39m(theta):  \u001b[39m# pylint: disable=arguments-differ\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Representation of the operator as a canonical matrix in the computational basis (static method).\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \n\u001b[0;32m    180\u001b[0m \u001b[39m    The canonical matrix is the textbook matrix representation that does not consider wires.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[39m            [ 0.2474,  0.9689]])\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m     c \u001b[39m=\u001b[39m qml\u001b[39m.\u001b[39;49mmath\u001b[39m.\u001b[39;49mcos(theta \u001b[39m/\u001b[39;49m \u001b[39m2\u001b[39;49m)\n\u001b[0;32m    200\u001b[0m     s \u001b[39m=\u001b[39m qml\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39msin(theta \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[0;32m    201\u001b[0m     \u001b[39mif\u001b[39;00m qml\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mget_interface(theta) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtensorflow\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\autoray\\autoray.py:79\u001b[0m, in \u001b[0;36mdo\u001b[1;34m(fn, like, *args, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Do function named ``fn`` on ``(*args, **kwargs)``, peforming single\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39mdispatch to retrieve ``fn`` based on whichever library defines the class of\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[39mthe ``args[0]``, or the ``like`` keyword argument if specified.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39m    <tf.Tensor: id=91, shape=(3, 3), dtype=float32>\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     78\u001b[0m backend \u001b[39m=\u001b[39m choose_backend(fn, \u001b[39m*\u001b[39margs, like\u001b[39m=\u001b[39mlike, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 79\u001b[0m \u001b[39mreturn\u001b[39;00m get_lib_fn(backend, fn)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\pennylane\\numpy\\wrapper.py:117\u001b[0m, in \u001b[0;36mtensor_wrapper.<locals>._wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m         tensor_kwargs[\u001b[39m\"\u001b[39m\u001b[39mrequires_grad\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _np\u001b[39m.\u001b[39many([i\u001b[39m.\u001b[39mrequires_grad \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tensor_args])\n\u001b[0;32m    116\u001b[0m \u001b[39m# evaluate the original object\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m res \u001b[39m=\u001b[39m obj(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, _np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m    120\u001b[0m     \u001b[39m# only if the output of the object is a ndarray,\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[39m# then convert to a PennyLane tensor\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     res \u001b[39m=\u001b[39m tensor(res, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtensor_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\autograd\\tracer.py:44\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m parents \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(box\u001b[39m.\u001b[39m_node \u001b[39mfor\u001b[39;00m _     , box \u001b[39min\u001b[39;00m boxed_args)\n\u001b[0;32m     43\u001b[0m argnums \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(argnum    \u001b[39mfor\u001b[39;00m argnum, _   \u001b[39min\u001b[39;00m boxed_args)\n\u001b[1;32m---> 44\u001b[0m ans \u001b[39m=\u001b[39m f_wrapped(\u001b[39m*\u001b[39;49margvals, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     45\u001b[0m node \u001b[39m=\u001b[39m node_constructor(ans, f_wrapped, argvals, kwargs, argnums, parents)\n\u001b[0;32m     46\u001b[0m \u001b[39mreturn\u001b[39;00m new_box(ans, trace, node)\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\autograd\\tracer.py:48\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[39mreturn\u001b[39;00m new_box(ans, trace, node)\n\u001b[0;32m     47\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 48\u001b[0m     \u001b[39mreturn\u001b[39;00m f_raw(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\writi\\OneDrive\\Desktop\\Algorithm-Research\\.venv\\Lib\\site-packages\\pennylane\\numpy\\tensor.py:157\u001b[0m, in \u001b[0;36mtensor.__array_ufunc__\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[39m# call the ndarray.__array_ufunc__ method to compute the result\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39m# of the vectorized ufunc\u001b[39;00m\n\u001b[0;32m    155\u001b[0m res \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m__array_ufunc__(ufunc, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 157\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, Operator):\n\u001b[0;32m    158\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[0;32m    160\u001b[0m \u001b[39mif\u001b[39;00m ufunc\u001b[39m.\u001b[39mnout \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32m<frozen abc>:117\u001b[0m, in \u001b[0;36m__instancecheck__\u001b[1;34m(cls, instance)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = qml.GradientDescentOptimizer(eta)\n",
    "#opt = qml.AdamOptimizer(stepsize=0.15, beta1 = 0.8)\n",
    "#opt = qml.QNGOptimizer(eta, qml.metric_tensor(cost_loc, metric_tensor_fn = metric_fn))\n",
    "\n",
    "\n",
    "#grad_vals = []\n",
    "cost_history = []\n",
    "w_history = []\n",
    "for it in range(steps):\n",
    "    if (cost_loc(w) < err_tol):\n",
    "        break\n",
    "    #cost_grad = qml.grad(cost_loc, argnum=0)(w)[0]\n",
    "    w, cost = opt.step_and_cost(cost_loc, w)\n",
    "\n",
    "    \n",
    "    #print(\"Step {:3d}       Cost_L = {:9.7f}        Cost_Grad = {:9.9f}\".format(it, cost, cost_grad))\n",
    "    print(\"Step {:3d}       Cost_L = {:9.9f}\".format(it, cost))\n",
    "    cost_history.append(cost)\n",
    "    w_history.append(w)\n",
    "    #grad_vals.append(cost_grad)\n",
    "\n",
    "#print(np.var(grad_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn\")\n",
    "plt.plot(cost_history, \"g\")\n",
    "plt.ylabel(\"Cost function\")\n",
    "plt.xlabel(\"Optimization steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def b_to_num():\n",
    "    U_b()\n",
    "    return qml.state()\n",
    "\n",
    "b_num = b_to_num()\n",
    "print(b_num)\n",
    "print(np.linalg.norm(b_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_inv = np.linalg.inv(A_num)\n",
    "x = np.dot(A_inv, b_num)\n",
    "\n",
    "c_probs = np.real((x / np.linalg.norm(x)) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_x = qml.device(\"default.qubit\", wires = n_qubits, shots = n_shots)\n",
    "\n",
    "@qml.qnode(dev_x, interface=\"autograd\")\n",
    "def prepare_and_sample(w):\n",
    "    init_weights, weights = reshape_weights(n_qubits, n_parameters, layers, w)\n",
    "    \n",
    "    # Variational circuit generating a guess for the solution vector |x>\n",
    "    variational_block(init_weights, weights)\n",
    "    # We assume that the system is measured in the computational basis.\n",
    "    # then sampling the device will give us a value of 0 or 1 for each qubit (n_qubits)\n",
    "    # this will be repeated for the total number of shots provided (n_shots)\n",
    "    return qml.sample()\n",
    "\n",
    "raw_samples = prepare_and_sample(w)\n",
    "\n",
    "# convert the raw samples (bit strings) into integers and count them\n",
    "samples = []\n",
    "\n",
    "for sam in raw_samples:\n",
    "    samples.append(int(\"\".join(str(bs) for bs in sam), base = 2))\n",
    "\n",
    "q_probs = np.bincount(samples) / n_shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_n^2 = \\n\", c_probs)\n",
    "\n",
    "print(\"|<x|n>|^2 = \\n\", q_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 4))\n",
    "\n",
    "ax1.bar(np.arange(0, 2 ** n_qubits), c_probs, color=\"blue\")\n",
    "ax1.set_xlim(-0.5, 2 ** n_qubits - 0.5)\n",
    "ax1.set_xlabel(\"Vector space basis\")\n",
    "ax1.set_title(\"Classical probabilities\")\n",
    "\n",
    "ax2.bar(np.arange(0, 2 ** n_qubits), q_probs, color=\"green\")\n",
    "ax2.set_xlim(-0.5, 2 ** n_qubits - 0.5)\n",
    "ax2.set_xlabel(\"Hilbert space basis\")\n",
    "ax2.set_title(\"Quantum probabilities\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
