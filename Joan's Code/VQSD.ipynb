{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bde12ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pennylane\n",
      "  Downloading PennyLane-0.33.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 651.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\chopi\\anaconda3\\lib\\site-packages (from pennylane) (4.4.0)\n",
      "Collecting autograd\n",
      "  Downloading autograd-1.6.2-py3-none-any.whl (49 kB)\n",
      "     -------------------------------------- 49.3/49.3 kB 830.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\chopi\\anaconda3\\lib\\site-packages (from pennylane) (1.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\chopi\\anaconda3\\lib\\site-packages (from pennylane) (1.23.5)\n",
      "Collecting autoray>=0.6.1\n",
      "  Downloading autoray-0.6.7-py3-none-any.whl (49 kB)\n",
      "     ---------------------------------------- 49.9/49.9 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: appdirs in c:\\users\\chopi\\anaconda3\\lib\\site-packages (from pennylane) (1.4.4)\n",
      "Collecting rustworkx\n",
      "  Downloading rustworkx-0.13.2-cp310-cp310-win_amd64.whl (1.4 MB)\n",
      "     ---------------------------------------- 1.4/1.4 MB 634.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: networkx in c:\\users\\chopi\\anaconda3\\lib\\site-packages (from pennylane) (2.8.4)\n",
      "Collecting cachetools\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Collecting semantic-version>=2.7\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\chopi\\anaconda3\\lib\\site-packages (from pennylane) (2.28.1)\n",
      "Requirement already satisfied: toml in c:\\users\\chopi\\anaconda3\\lib\\site-packages (from pennylane) (0.10.2)\n",
      "Collecting pennylane-lightning>=0.33\n",
      "  Downloading PennyLane_Lightning-0.33.1-cp310-cp310-win_amd64.whl (4.2 MB)\n",
      "     ---------------------------------------- 4.2/4.2 MB 591.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: future>=0.15.2 in c:\\users\\chopi\\anaconda3\\lib\\site-packages (from autograd->pennylane) (0.18.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\chopi\\anaconda3\\lib\\site-packages (from requests->pennylane) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\chopi\\anaconda3\\lib\\site-packages (from requests->pennylane) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chopi\\anaconda3\\lib\\site-packages (from requests->pennylane) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chopi\\anaconda3\\lib\\site-packages (from requests->pennylane) (3.4)\n",
      "Installing collected packages: semantic-version, rustworkx, cachetools, autoray, autograd, pennylane-lightning, pennylane\n",
      "Successfully installed autograd-1.6.2 autoray-0.6.7 cachetools-5.3.2 pennylane-0.33.1 pennylane-lightning-0.33.1 rustworkx-0.13.2 semantic-version-2.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pennylane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "37885a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92c9f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml \n",
    "from pennylane import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a4200023",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2\n",
    "n = 2*m\n",
    "def test_prep(m):\n",
    "    for i in range(2*m):\n",
    "        qml.Hadamard(i)\n",
    "#    return [qml.expval(qml.PauliZ(i)) for i in range(2*m)]\n",
    "#drawer = qml.draw(test_prep)\n",
    "#print(drawer(2))\n",
    "#test_prep(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7d6dfec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "#Make angles equal in the ith subsystem of registers 1 and 2\n",
    "#param needs to be specifiable with m angles\n",
    "def ansatz(param, m):\n",
    "    for i in range(2*m):\n",
    "        qml.RY(param[i], wires = i)\n",
    "        qml.RX(np.pi/2, wires = i)\n",
    "#drawer = qml.draw(ansatz)\n",
    "#print(drawer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0d887763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_fun(m):\n",
    "    for i in range(m):\n",
    "        qml.CNOT(wires = [i,i+m])\n",
    "#drawer = qml.draw(cost_fun)\n",
    "#print(drawer(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "93c04bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 1000\n",
    "m = 2\n",
    "n = 2*m\n",
    "dev = qml.device(\"default.qubit\", wires = n, shots = s)\n",
    "@qml.qnode(dev, interface = \"autograd\")\n",
    "def circuit(param, m):\n",
    "    test_prep(m)\n",
    "    ansatz(param, m)\n",
    "    cost_fun(m)\n",
    "    return qml.probs(wires = [i for i in range(2*m)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "603d4791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VQSD(param):\n",
    "    return circuit(param, m)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9eb105e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "t = []\n",
    "for i in range(n):\n",
    "    t.append(0.0)\n",
    "theta = np.array(t, requires_grad=True)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "31b060b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.049\n"
     ]
    }
   ],
   "source": [
    "diag = VQSD(theta)\n",
    "print(diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3a049540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0., 0., 0., 0.], requires_grad=True)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the values of the circuit parameter\n",
    "angle = [theta]\n",
    "#print(angle)\n",
    "#len(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f0100812",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Grad only applies to real scalar-output functions. Try jacobian, elementwise_grad or holomorphic_grad.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m conv_tol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-06\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iterations):\n\u001b[1;32m----> 6\u001b[0m     theta, prev_diag \u001b[38;5;241m=\u001b[39m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_and_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mVQSD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     diag\u001b[38;5;241m.\u001b[39mappend(VQSD(theta))\n\u001b[0;32m      9\u001b[0m     angle\u001b[38;5;241m.\u001b[39mappend(theta)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\optimize\\gradient_descent.py:59\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.step_and_cost\u001b[1;34m(self, objective_fn, grad_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_and_cost\u001b[39m(\u001b[38;5;28mself\u001b[39m, objective_fn, \u001b[38;5;241m*\u001b[39margs, grad_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;124;03m\"\"\"Update trainable arguments with one step of the optimizer and return the corresponding\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    objective function value prior to the step.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m        If single arg is provided, list [array] is replaced by array.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m     g, forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m     new_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_grad(g, args)\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m forward \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\optimize\\gradient_descent.py:117\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.compute_grad\u001b[1;34m(objective_fn, args, kwargs, grad_fn)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Compute gradient of the objective function at the given point and return it along with\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03mthe objective function forward pass (if available).\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;124;03m    will not be evaluted and instead ``None`` will be returned.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m g \u001b[38;5;241m=\u001b[39m get_gradient(objective_fn) \u001b[38;5;28;01mif\u001b[39;00m grad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m grad_fn\n\u001b[1;32m--> 117\u001b[0m grad \u001b[38;5;241m=\u001b[39m g(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(g, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    120\u001b[0m num_trainable_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\_grad.py:118\u001b[0m, in \u001b[0;36mgrad.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ()\n\u001b[1;32m--> 118\u001b[0m grad_value, ans \u001b[38;5;241m=\u001b[39m grad_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward \u001b[38;5;241m=\u001b[39m ans\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad_value\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\autograd\\wrap_util.py:20\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(args[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnum)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unary_operator(unary_f, x, \u001b[38;5;241m*\u001b[39mnary_op_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnary_op_kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\_grad.py:139\u001b[0m, in \u001b[0;36mgrad._grad_with_forward\u001b[1;34m(fun, x)\u001b[0m\n\u001b[0;32m    136\u001b[0m vjp, ans \u001b[38;5;241m=\u001b[39m _make_vjp(fun, x)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vspace(ans)\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrad only applies to real scalar-output functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry jacobian, elementwise_grad or holomorphic_grad.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    142\u001b[0m     )\n\u001b[0;32m    144\u001b[0m grad_value \u001b[38;5;241m=\u001b[39m vjp(vspace(ans)\u001b[38;5;241m.\u001b[39mones())\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad_value, ans\n",
      "\u001b[1;31mTypeError\u001b[0m: Grad only applies to real scalar-output functions. Try jacobian, elementwise_grad or holomorphic_grad."
     ]
    }
   ],
   "source": [
    "opt = qml.GradientDescentOptimizer(stepsize=0.4)\n",
    "max_iterations = 100\n",
    "conv_tol = 1e-06\n",
    "\n",
    "for n in range(max_iterations):\n",
    "    theta, prev_diag = opt.step_and_cost(VQSD, theta)\n",
    "\n",
    "    diag.append(VQSD(theta))\n",
    "    angle.append(theta)\n",
    "\n",
    "    conv = np.abs(energy[-1] - prev_diag)\n",
    "\n",
    "    if n % 2 == 0:\n",
    "        print(f\"Step = {n},  Energy = {diag[-1]:.8f} Ha\")\n",
    "\n",
    "    if conv <= conv_tol:\n",
    "        break\n",
    "\n",
    "print(\"\\n\" f\"Final value of the ground-state energy = {energy[-1]:.8f} Ha\")\n",
    "print(\"\\n\" f\"Optimal value of the circuit parameter = {angle[-1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
